#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PRå¤„ç†Pipeline
ç›´æ¥è°ƒç”¨ç°æœ‰æ¨¡å—è·å–PRæ•°æ®å¹¶è¿›è¡Œåˆ†æå¤„ç†

ä½¿ç”¨æ–¹æ³•:
python process_pr_pipeline.py <owner> <repo> <start_pr> <end_pr> [--output output_dir]

ç¤ºä¾‹:
python process_pr_pipeline.py JabRef jabref 10590 10600
python process_pr_pipeline.py JabRef jabref 10590 10600 --output results/jabref_batch
"""

import argparse
import json
import os
import sys
import time
import glob
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

# å¯¼å…¥ç°æœ‰æ¨¡å—
from get_pr_comments_py_github import GitHubPRCommentsFetcher
import extract_pipline_preliminary as extract_module
from util.logging import default_logger


def parse_pr_list(pr_args: List[str]) -> List[int]:
    """
    è§£æPRç¼–å·åˆ—è¡¨ï¼Œæ”¯æŒå•ä¸ªæ•°å­—å’ŒèŒƒå›´æ ¼å¼
    
    Args:
        pr_args: PRå‚æ•°åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å¯ä»¥æ˜¯æ•°å­—æˆ–èŒƒå›´ï¼ˆå¦‚ "10590-10600"ï¼‰
        
    Returns:
        List[int]: è§£æåçš„PRç¼–å·åˆ—è¡¨ï¼ˆå»é‡å¹¶æ’åºï¼‰
        
    Raises:
        ValueError: å½“è¾“å…¥æ ¼å¼æ— æ•ˆæ—¶
        
    Examples:
        parse_pr_list(["10590", "10595", "10600-10610"]) 
        # è¿”å› [10590, 10595, 10600, 10601, 10602, ..., 10610]
    """
    pr_numbers = set()
    
    for arg in pr_args:
        arg = arg.strip()
        
        if '-' in arg and not arg.startswith('-'):
            # å¤„ç†èŒƒå›´æ ¼å¼ "start-end"
            try:
                parts = arg.split('-')
                if len(parts) != 2:
                    raise ValueError(f"æ— æ•ˆçš„èŒƒå›´æ ¼å¼: {arg}")
                
                start_pr = int(parts[0])
                end_pr = int(parts[1])
                
                if start_pr > end_pr:
                    raise ValueError(f"èµ·å§‹PRç¼–å·ä¸èƒ½å¤§äºç»“æŸPRç¼–å·: {arg}")
                
                # æ·»åŠ èŒƒå›´å†…çš„æ‰€æœ‰æ•°å­—
                pr_numbers.update(range(start_pr, end_pr + 1))
                
            except ValueError as e:
                if "invalid literal for int()" in str(e):
                    raise ValueError(f"èŒƒå›´æ ¼å¼ä¸­åŒ…å«æ— æ•ˆæ•°å­—: {arg}")
                else:
                    raise e
        else:
            # å¤„ç†å•ä¸ªæ•°å­—
            try:
                pr_number = int(arg)
                if pr_number <= 0:
                    raise ValueError(f"PRç¼–å·å¿…é¡»ä¸ºæ­£æ•´æ•°: {arg}")
                pr_numbers.add(pr_number)
            except ValueError:
                raise ValueError(f"æ— æ•ˆçš„PRç¼–å·: {arg}")
    
    if not pr_numbers:
        raise ValueError("æœªæä¾›æœ‰æ•ˆçš„PRç¼–å·")
    
    return sorted(list(pr_numbers))


class PRProcessor:
    def __init__(self, owner: str, repo: str, config_path: str = "config.yaml", token_path: str = "PAT.token"):
        """
        åˆå§‹åŒ–PRå¤„ç†å™¨
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            token_path: GitHub PAT tokenæ–‡ä»¶è·¯å¾„
        """
        self.owner = owner
        self.repo = repo
        
        # åˆå§‹åŒ–GitHub fetcher
        self.fetcher = GitHubPRCommentsFetcher(config_path, token_path)
    
    def fetch_pr_data(self, pr_number: int) -> Optional[Dict]:
        """
        è·å–å•ä¸ªPRçš„æ•°æ® - ç›´æ¥è°ƒç”¨get_pr_comments_py_github
        
        Args:
            pr_number: PRç¼–å·
            
        Returns:
            Dict: PRæ•°æ®ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            default_logger.info(f"å¼€å§‹è·å–PR #{pr_number}çš„æ•°æ®")
            pr_data = self.fetcher.fetch_pr_data(self.owner, self.repo, pr_number, fetch_code_snippet=False)
            
            if isinstance(pr_data, dict) and "error" in pr_data:
                default_logger.error(f"PR #{pr_number} è·å–å¤±è´¥: {pr_data['error']}")
                return None
            
            default_logger.info(f"PR #{pr_number} æ•°æ®è·å–æˆåŠŸ")
            return pr_data
            
        except Exception as e:
            default_logger.error(f"PR #{pr_number} è·å–å¼‚å¸¸: {str(e)}")
            return None
    
    def load_existing_pr_data(self, pr_data_file: Path) -> Optional[Dict]:
        """
        å®‰å…¨åœ°è¯»å–å·²å­˜åœ¨çš„PRæ•°æ®æ–‡ä»¶
        
        Args:
            pr_data_file: PRæ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: è¯»å–çš„PRæ•°æ®ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if not pr_data_file.exists():
            return None
            
        try:
            with open(pr_data_file, 'r', encoding='utf-8') as f:
                pr_data = json.load(f)
            default_logger.info(f"æˆåŠŸä»ç¼“å­˜è¯»å–PRæ•°æ®: {pr_data_file.name}")
            return pr_data
        except (json.JSONDecodeError, IOError) as e:
            default_logger.warning(f"è¯»å–PRæ•°æ®æ–‡ä»¶å¤±è´¥ï¼Œå°†é‡æ–°è·å–: {pr_data_file.name}, é”™è¯¯: {str(e)}")
            return None
    
    def check_suggestions_file_exists(self, output_path: Path, pr_number: int) -> Optional[Path]:
        """
        æ£€æŸ¥å»ºè®®ç»“æœæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        
        Args:
            output_path: è¾“å‡ºç›®å½•è·¯å¾„
            pr_number: PRç¼–å·
            
        Returns:
            Path: å¦‚æœå­˜åœ¨è¿”å›æ–‡ä»¶è·¯å¾„ï¼Œå¦åˆ™è¿”å›None
        """
        # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„å»ºè®®æ–‡ä»¶ï¼ˆæ”¯æŒæ—¶é—´æˆ³æ¨¡å¼ï¼‰
        pattern = f"all_suggestions_{pr_number}_*.json"
        suggestion_files = list(output_path.glob(pattern))
        
        if suggestion_files:
            # è¿”å›æœ€æ–°çš„æ–‡ä»¶
            latest_file = max(suggestion_files, key=lambda p: p.stat().st_mtime)
            default_logger.info(f"å‘ç°å·²å­˜åœ¨çš„å»ºè®®æ–‡ä»¶: {latest_file.name}")
            return latest_file
        
        return None

    def extract_suggestions(self, pr_data: Dict, pr_number: int) -> Optional[Dict]:
        """
        ä»PRæ•°æ®ä¸­æå–å»ºè®® - ç›´æ¥è°ƒç”¨extract_pipline_preliminary
        
        Args:
            pr_data: PRæ•°æ®
            pr_number: PRç¼–å·
            
        Returns:
            Dict: æå–çš„å»ºè®®æ•°æ®ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            default_logger.info(f"å¼€å§‹å¤„ç†PR #{pr_number}çš„å»ºè®®æå–")
            
            # å‡†å¤‡PRä¿¡æ¯
            pr_info = {
                "owner": self.owner,
                "repo": self.repo,
                "pr_number": pr_number,
            }
            
            # è·å–å¿…è¦çš„æ•°æ®
            review_threads = pr_data.get("reviewThreads", [])
            commits = pr_data.get("commits", [])
            global_discussions = pr_data.get("globalDiscussions", [])
            
            # ç›´æ¥è°ƒç”¨ç°æœ‰çš„extractæ¨¡å—å‡½æ•°
            review_thread_suggestions = extract_module.extract_review_thread_pipeline(review_threads, global_discussions)
            comment_suggestions = extract_module.extract_comment_and_review_pipeline(global_discussions)
            
            # æŒ‰ç…§ç°æœ‰æ ¼å¼ç»„è£…ç»“æœ
            all_suggestions = {
                "reviewThreadSuggestions": review_thread_suggestions,
                "commentSuggestions": comment_suggestions,
            }
            
            default_logger.info(f"PR #{pr_number} å»ºè®®æå–å®Œæˆ")
            return all_suggestions
            
        except Exception as e:
            default_logger.error(f"PR #{pr_number} å»ºè®®æå–å¼‚å¸¸: {str(e)}")
            return None
    
    def process_pr_list(self, pr_numbers: List[int], output_dir: str = "output") -> None:
        """
        å¤„ç†PRåˆ—è¡¨ï¼Œæ”¯æŒåç»­æ‰©å±•å…¶ä»–å¤„ç†ç¯èŠ‚
        
        Args:
            pr_numbers: PRç¼–å·åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"å¼€å§‹å¤„ç† {self.owner}/{self.repo} çš„ {len(pr_numbers)} ä¸ªPR: {pr_numbers}")
        
        for pr_number in pr_numbers:
            print(f"\nå¤„ç† PR #{pr_number}")
            
            # é¦–å…ˆæ£€æŸ¥å»ºè®®ç»“æœæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            # existing_suggestions_file = self.check_suggestions_file_exists(output_path, pr_number)
            # if existing_suggestions_file:
            #     print(f"âš¡ PR #{pr_number} å»ºè®®æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†: {existing_suggestions_file.name}")
            #     default_logger.info(f"PR #{pr_number} è·³è¿‡å¤„ç†ï¼Œå»ºè®®æ–‡ä»¶å·²å­˜åœ¨: {existing_suggestions_file}")
            #     continue
            
            # æ­¥éª¤1: è·å–PRæ•°æ® (æ£€æŸ¥ç¼“å­˜)
            pr_data_file = output_path / f"pr_data_py_github_{pr_number}.json"
            pr_data = self.load_existing_pr_data(pr_data_file)
            
            if pr_data is not None:
                print(f"ğŸ“ PR #{pr_number} ä½¿ç”¨ç¼“å­˜æ•°æ®")
            else:
                print(f"ğŸ”„ PR #{pr_number} é‡æ–°è·å–æ•°æ®")
                pr_data = self.fetch_pr_data(pr_number)
                if pr_data is None:
                    print(f"âœ— PR #{pr_number} æ•°æ®è·å–å¤±è´¥")
                    continue
                
                # ä¿å­˜åŸå§‹PRæ•°æ® (æŒ‰ç…§ç°æœ‰æ ¼å¼)
                try:
                    with open(pr_data_file, 'w', encoding='utf-8') as f:
                        json.dump(pr_data, f, indent=2, ensure_ascii=False)
                    default_logger.info(f"ä¿å­˜PR #{pr_number}åŸå§‹æ•°æ®æˆåŠŸ: {pr_data_file}")
                except Exception as e:
                    default_logger.error(f"ä¿å­˜PR #{pr_number}åŸå§‹æ•°æ®å¤±è´¥: {str(e)}")
            
            # æ­¥éª¤2: æå–å»ºè®®
            print(f"ğŸ¤– PR #{pr_number} å¼€å§‹å»ºè®®æå–")
            suggestions = self.extract_suggestions(pr_data, pr_number)
            if suggestions is None:
                print(f"âœ— PR #{pr_number} å»ºè®®æå–å¤±è´¥")
                continue
            
            # ä¿å­˜å»ºè®®ç»“æœ (æŒ‰ç…§ç°æœ‰æ ¼å¼)
            timestamp = datetime.now().strftime("%a %b %d %H:%M:%S %Y")
            suggestions_file = output_path / f"all_suggestions_{pr_number}_{timestamp}.json"
            try:
                with open(suggestions_file, 'w', encoding='utf-8') as f:
                    json.dump(suggestions, f, indent=2, ensure_ascii=False)
                print(f"âœ“ PR #{pr_number} å¤„ç†å®Œæˆ")
                default_logger.info(f"ä¿å­˜PR #{pr_number}å»ºè®®æˆåŠŸ: {suggestions_file}")
            except Exception as e:
                default_logger.error(f"ä¿å­˜PR #{pr_number}å»ºè®®å¤±è´¥: {str(e)}")
            
            # æ‰©å±•ç‚¹: å¯åœ¨æ­¤å¤„æ·»åŠ æ›´å¤šå¤„ç†ç¯èŠ‚
            # ä¾‹å¦‚: self.additional_processing_step(pr_data, suggestions, pr_number)
        
        print(f"\nå¤„ç†å®Œæˆï¼")


def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(
        description="PRæ•°æ®è·å–å’Œå»ºè®®æå–Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¤„ç†å•ä¸ªPR
  python process_pr_pipeline.py JabRef jabref --prs 10590
  
  # å¤„ç†å¤šä¸ªä¸è¿ç»­çš„PR
  python process_pr_pipeline.py JabRef jabref --prs 10590 10595 10600
  
  # å¤„ç†è¿ç»­èŒƒå›´çš„PR
  python process_pr_pipeline.py JabRef jabref --prs 10590-10600
  
  # æ··åˆä½¿ç”¨ï¼ˆå•ä¸ªã€èŒƒå›´ã€å¤šä¸ªï¼‰
  python process_pr_pipeline.py JabRef jabref --prs 10590 10595 10600-10610 10615
  
  # æŒ‡å®šè¾“å‡ºç›®å½•
  python process_pr_pipeline.py JabRef jabref --prs 10590-10600 --output results/jabref_batch
        """
    )
    
    parser.add_argument("owner", help="ä»“åº“æ‰€æœ‰è€…")
    parser.add_argument("repo", help="ä»“åº“åç§°")
    parser.add_argument(
        "--prs", 
        nargs='+', 
        required=True,
        help="PRç¼–å·åˆ—è¡¨ï¼Œæ”¯æŒå•ä¸ªæ•°å­—(10590)ã€èŒƒå›´(10590-10600)æˆ–æ··åˆä½¿ç”¨"
    )
    parser.add_argument(
        "--output",
        default="output",
        help="è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: output)"
    )
    parser.add_argument(
        "--config",
        default="config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)"
    )
    parser.add_argument(
        "--token",
        default="PAT.token",
        help="GitHub Personal Access Tokenæ–‡ä»¶è·¯å¾„ (é»˜è®¤: PAT.token)"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(args.config):
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ {args.config} ä¸å­˜åœ¨")
        sys.exit(1)
    
    # æ£€æŸ¥tokenæ–‡ä»¶
    if not os.path.exists(args.token):
        print(f"é”™è¯¯: tokenæ–‡ä»¶ {args.token} ä¸å­˜åœ¨")
        sys.exit(1)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ˆç”¨äºLLM APIè°ƒç”¨ï¼‰
    if not os.environ.get("DEEPSEEK_API_KEY"):
        print("è­¦å‘Š: æœªè®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ï¼Œå»ºè®®æå–åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        sys.exit(1)
    
    try:
        # è§£æPRç¼–å·åˆ—è¡¨
        pr_numbers = parse_pr_list(args.prs)
        print(f"è§£æåˆ° {len(pr_numbers)} ä¸ªPRç¼–å·: {pr_numbers}")
        
        # åˆ›å»ºå¤„ç†å™¨
        processor = PRProcessor(args.owner, args.repo, args.config, args.token)
        
        # å¼€å§‹å¤„ç†
        processor.process_pr_list(pr_numbers, args.output)
        
    except ValueError as e:
        print(f"PRç¼–å·è§£æé”™è¯¯: {str(e)}")
        print("è¯·æ£€æŸ¥PRç¼–å·æ ¼å¼ï¼Œæ”¯æŒçš„æ ¼å¼ï¼š")
        print("  - å•ä¸ªæ•°å­—: 10590")
        print("  - èŒƒå›´æ ¼å¼: 10590-10600")
        print("  - æ··åˆä½¿ç”¨: 10590 10595 10600-10610")
        sys.exit(1)
    except KeyboardInterrupt:
        print(f"\n\nç”¨æˆ·ä¸­æ–­å¤„ç†")
        sys.exit(1)
    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()